{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Recognition Attendance System\n",
        "\n",
        "Welcome! This notebook walks you through the full pipeline used in this repository:\n",
        "\n",
        "1. **Prepare the dataset** (images organized by person in `../data/`)\n",
        "2. **Encode faces** and **train a classifier**\n",
        "3. **Save trained artifacts** to `../models/`\n",
        "4. **Run recognition** (image or webcam) and **log attendance** to `../outputs/attendance.csv`\n",
        "\n",
        "This notebook mirrors the logic of the Python scripts in `src/` but adds explanations and runnable cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Structure (expected)\n",
        "```\n",
        "face-recognition-attendance-system/\n",
        "â”‚â”€â”€ data/                          # raw images, organized by person\n",
        "â”‚   â”œâ”€â”€ person1/\n",
        "â”‚   â”œâ”€â”€ person2/\n",
        "â”‚   â””â”€â”€ ...\n",
        "â”‚\n",
        "â”‚â”€â”€ models/                        # trained models, encodings\n",
        "â”‚   â”œâ”€â”€ encodings.pkl\n",
        "â”‚   â””â”€â”€ classifier.pkl\n",
        "â”‚\n",
        "â”‚â”€â”€ notebook/\n",
        "â”‚   â””â”€â”€ face_recognition_demo.ipynb\n",
        "â”‚\n",
        "â”‚â”€â”€ src/\n",
        "â”‚   â”œâ”€â”€ train_model.py\n",
        "â”‚   â”œâ”€â”€ test_model.py\n",
        "â”‚   â””â”€â”€ utils.py (optional)\n",
        "â”‚\n",
        "â”‚â”€â”€ outputs/\n",
        "â”‚   â””â”€â”€ attendance.csv\n",
        "â”‚\n",
        "â”‚â”€â”€ requirements.txt\n",
        "â”‚â”€â”€ README.md\n",
        "â”‚â”€â”€ .gitignore\n",
        "```\n",
        "\n",
        "**Note:** This notebook assumes it lives inside `notebook/`. All paths are resolved relative to the project root (`..`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup & Imports\n",
        "Install dependencies (if needed) and import libraries. If you're running inside a fresh environment, uncomment the pip command to install from `requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE_DIR: c:\\Users\\hp\\Downloads\n",
            "DATA_DIR: c:\\Users\\hp\\Downloads\\data\n",
            "MODELS_DIR: c:\\Users\\hp\\Downloads\\models\n",
            "OUTPUTS_DIR: c:\\Users\\hp\\Downloads\\outputs\n"
          ]
        }
      ],
      "source": [
        "# Optional: install dependencies from the repo root\n",
        "# !pip install -r ../requirements.txt\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Resolve key paths relative to this notebook (located in ../notebook)\n",
        "BASE_DIR = os.getcwd()  # gets current working directory (where notebook runs)\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "OUTPUTS_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
        "\n",
        "ATTENDANCE_FILE = os.path.join(OUTPUTS_DIR, \"attendance.csv\")\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)\n",
        "print(\"OUTPUTS_DIR:\", OUTPUTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Dataset Preparation\n",
        "Images should be placed in `../data/<person_name>/image.jpg`. We will:\n",
        "\n",
        "- Load each image\n",
        "- Detect the face and compute a 128-D embedding using `face_recognition`\n",
        "- Build arrays: `encodings` (features) and `labels` (person names)\n",
        "\n",
        "If an image doesn't contain a detectable face, it will be skipped with a warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Dataset path not found: c:\\Users\\hp\\data",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(labels))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unique classes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(encodings), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m---> 33\u001b[0m encodings, labels \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of encodings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(encodings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncodings shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencodings\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mencodings\u001b[38;5;241m.\u001b[39msize\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[2], line 16\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m encodings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dataset_path):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset path not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dataset_path):\n\u001b[0;32m     19\u001b[0m     person_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, person_name)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: Dataset path not found: c:\\Users\\hp\\data"
          ]
        }
      ],
      "source": [
        "def get_face_encodings(image_path):\n",
        "    \"\"\"Return the 128-D face encoding for the first face found in the image, or None.\"\"\"\n",
        "    try:\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        encs = face_recognition.face_encodings(image)\n",
        "        if encs:\n",
        "            return encs[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "def prepare_dataset(dataset_path):\n",
        "    labels = []\n",
        "    encodings = []\n",
        "    if not os.path.isdir(dataset_path):\n",
        "        raise FileNotFoundError(f\"Dataset path not found: {dataset_path}\")\n",
        "\n",
        "    for person_name in os.listdir(dataset_path):\n",
        "        person_folder = os.path.join(dataset_path, person_name)\n",
        "        if os.path.isdir(person_folder):\n",
        "            for image_name in os.listdir(person_folder):\n",
        "                image_path = os.path.join(person_folder, image_name)\n",
        "                print(f\"Processing {image_path}...\")\n",
        "                encoding = get_face_encodings(image_path)\n",
        "                if encoding is not None:\n",
        "                    encodings.append(encoding)\n",
        "                    labels.append(person_name)\n",
        "                else:\n",
        "                    print(f\"Warning: No encoding found for image: {image_path}\")\n",
        "    print(f\"Found {len(np.unique(labels))} unique classes.\")\n",
        "    return np.array(encodings), np.array(labels)\n",
        "\n",
        "encodings, labels = prepare_dataset(DATA_DIR)\n",
        "print(f\"Number of encodings: {len(encodings)}\")\n",
        "print(f\"Encodings shape: {encodings.shape if encodings.size else 'Empty'}\")\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "print(f\"Unique classes: {np.unique(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Train the Classifier (SVM)\n",
        "We split the data into train/test sets and train a simple SVM (`svm.SVC`) on the embeddings. \n",
        "\n",
        "**Why this works:** `face_recognition` already gives a strong embedding where same-person faces are close together in the 128-D space. A linear or RBF SVM can then separate classes effectively.\n",
        "\n",
        "If you only have one class (one person) or too few images, training will fail â€” add more data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if encodings.size == 0 or len(labels) == 0:\n",
        "    raise RuntimeError(\"No encodings or labels found. Check your dataset in ../data.\")\n",
        "\n",
        "if len(np.unique(labels)) < 2:\n",
        "    raise RuntimeError(\"Less than 2 unique classes found. Add more people to ../data.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encodings, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(\"Training set classes:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Testing set classes:\", np.unique(y_test, return_counts=True))\n",
        "\n",
        "clf = svm.SVC(gamma='scale')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Save Artifacts to `../models/`\n",
        "We persist two files so you can reuse them without retraining:\n",
        "\n",
        "- `encodings.pkl`: numpy array of embeddings and their labels (for later retraining/expansion)\n",
        "- `classifier.pkl`: trained SVM classifier\n",
        "\n",
        "These mirror what your scripts in `src/` generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_path = os.path.join(MODELS_DIR, 'encodings.pkl')\n",
        "clf_path = os.path.join(MODELS_DIR, 'classifier.pkl')\n",
        "\n",
        "with open(enc_path, 'wb') as f:\n",
        "    pickle.dump((encodings, labels), f)\n",
        "\n",
        "with open(clf_path, 'wb') as f:\n",
        "    pickle.dump(clf, f)\n",
        "\n",
        "print(f\"Saved encodings â†’ {enc_path}\")\n",
        "print(f\"Saved classifier â†’ {clf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) (Optional) Test on a Single Image\n",
        "Use the trained classifier + stored encodings to predict a person in a static image. This is handy for quick validation before trying the webcam.\n",
        "\n",
        "ðŸ‘‰ Place a test image at a known path (e.g., `../data/person1/some_image.jpg`) and update the `TEST_IMAGE_PATH` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image_path, known_encodings, known_labels, clf):\n",
        "    image_bgr = cv2.imread(image_path)\n",
        "    if image_bgr is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(image_rgb)\n",
        "    encs = face_recognition.face_encodings(image_rgb, boxes)\n",
        "\n",
        "    results = []\n",
        "    for enc, (top, right, bottom, left) in zip(encs, boxes):\n",
        "        # Option A: classifier prediction (trained SVM)\n",
        "        pred_name = clf.predict([enc])[0]\n",
        "        results.append((pred_name, (top, right, bottom, left)))\n",
        "    return image_bgr, results\n",
        "\n",
        "# Example usage (uncomment and set a valid path):\n",
        "# TEST_IMAGE_PATH = os.path.join(DATA_DIR, 'person1', 'your_test_image.jpg')\n",
        "# with open(os.path.join(MODELS_DIR, 'classifier.pkl'), 'rb') as f:\n",
        "#     loaded_clf = pickle.load(f)\n",
        "# with open(os.path.join(MODELS_DIR, 'encodings.pkl'), 'rb') as f:\n",
        "#     loaded_encs, loaded_labels = pickle.load(f)\n",
        "# img, preds = predict_image(TEST_IMAGE_PATH, loaded_encs, loaded_labels, loaded_clf)\n",
        "# for name, (t,r,b,l) in preds:\n",
        "#     cv2.rectangle(img, (l,t), (r,b), (0,255,0), 2)\n",
        "#     cv2.putText(img, name, (l, t-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
        "# cv2.imshow('Prediction', img)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Attendance Logging\n",
        "When a face is recognized, we log it to `../outputs/attendance.csv` **once per person per day**. The logic is:\n",
        "\n",
        "- If the CSV doesn't exist, create it with a header\n",
        "- If the person is already logged today, skip\n",
        "- Otherwise, append a new row with `Name, Date, Time`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mark_attendance(name, filename=ATTENDANCE_FILE):\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime('%Y-%m-%d')   # Date\n",
        "    tm_string = now.strftime('%H:%M:%S')   # Time\n",
        "\n",
        "    file_exists = os.path.isfile(filename)\n",
        "\n",
        "    # Ensure header exists\n",
        "    if not file_exists:\n",
        "        with open(filename, 'w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"Name\", \"Date\", \"Time\"])\n",
        "\n",
        "    # Check if this name already has attendance for today\n",
        "    with open(filename, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)  # skip header\n",
        "        for row in reader:\n",
        "            if len(row) >= 2 and row[0] == name and row[1] == dt_string:\n",
        "                print(f\"{name} already marked for {dt_string}\")\n",
        "                return\n",
        "\n",
        "    # Append new record\n",
        "    with open(filename, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([name, dt_string, tm_string])\n",
        "        print(f\"Attendance marked for {name} at {dt_string} {tm_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Real-Time Recognition (Webcam)\n",
        "This cell starts your webcam and performs real-time face recognition. For each new person recognized in the current session, attendance is logged once per day.\n",
        "\n",
        "**Controls:** Press `q` to quit.\n",
        "\n",
        "**Note:** `face_recognition` expects RGB images, while OpenCV captures in BGR. We convert BGR â†’ RGB before encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recognize_faces(frame, clf, distance_threshold=0.6):\n",
        "    # Convert BGR â†’ RGB for face_recognition\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    face_locations = face_recognition.face_locations(rgb)\n",
        "    face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
        "    names = []\n",
        "\n",
        "    for face_encoding in face_encodings:\n",
        "        # Predict with the trained classifier directly\n",
        "        try:\n",
        "            name = clf.predict([face_encoding])[0]\n",
        "            names.append(name)\n",
        "        except Exception as e:\n",
        "            names.append(\"Unknown\")\n",
        "    return face_locations, names\n",
        "\n",
        "def run_webcam_recognition():\n",
        "    # Load classifier\n",
        "    with open(os.path.join(MODELS_DIR, 'classifier.pkl'), 'rb') as f:\n",
        "        clf = pickle.load(f)\n",
        "\n",
        "    recognized_names = set()  # in-session dedupe to avoid spamming console/CSV\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(\"Could not open webcam. Is a camera available?\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture image from camera.\")\n",
        "            break\n",
        "\n",
        "        face_locations, names = recognize_faces(frame, clf)\n",
        "        for (top, right, bottom, left), name in zip(face_locations, names):\n",
        "            if name != \"Unknown\" and name not in recognized_names:\n",
        "                recognized_names.add(name)\n",
        "                mark_attendance(name)\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow('Face Recognition - Press q to quit', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# To run the webcam demo, uncomment:\n",
        "# run_webcam_recognition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Notes, Troubleshooting & Next Steps\n",
        "- **Lighting & camera angle:** Bad lighting or extreme angles reduce accuracy.\n",
        "- **Image quality:** Use clear, frontal images for each person (several per person recommended).\n",
        "- **Thresholds:** You can adjust SVM parameters or switch to distance-based matching with a threshold (e.g., 0.6) against saved encodings.\n",
        "- **Liveness/anti-spoofing:** This simple system can be fooled by phone photos. To mitigate, consider adding liveness detection (eye blink, depth/IR camera, texture analysis, challenge-response).\n",
        "- **Per-day CSV:** Currently logs to a single `attendance.csv`. You can change to daily files like `attendance_YYYY-MM-DD.csv` if needed.\n",
        "- **Performance:** For many users, consider caching encodings, using GPU-accelerated libraries, or batching frames.\n",
        "\n",
        "If you encounter issues, verify:\n",
        "1) Paths (`DATA_DIR`, `MODELS_DIR`, `OUTPUTS_DIR`) are correct\n",
        "2) Camera is available and accessible\n",
        "3) You have at least 2 classes and enough images per class"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
