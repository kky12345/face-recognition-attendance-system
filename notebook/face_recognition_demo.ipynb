{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b5167f2",
      "metadata": {},
      "source": [
        "# Face Recognition Attendance System\n",
        "\n",
        "Welcome! This notebook walks you through the full pipeline used in this repository:\n",
        "\n",
        "1. **Prepare the dataset** (images organized by person in `../data/`)\n",
        "2. **Encode faces** and **train a classifier**\n",
        "3. **Save trained artifacts** to `../models/`\n",
        "4. **Run recognition** (image or webcam) and **log attendance** to `../outputs/attendance.csv`\n",
        "\n",
        "This notebook mirrors the logic of the Python scripts in `src/` but adds explanations and runnable cells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada92550",
      "metadata": {},
      "source": [
        "## Project Structure \n",
        "```\n",
        "face-recognition-attendance-system/\n",
        "â”‚â”€â”€ data/                          # raw images, organized by person\n",
        "â”‚   â”œâ”€â”€ person1/\n",
        "â”‚   â”œâ”€â”€ person2/\n",
        "â”‚   â””â”€â”€ ...\n",
        "â”‚\n",
        "â”‚â”€â”€ models/                        # trained models, encodings\n",
        "â”‚   â”œâ”€â”€ encodings.pkl\n",
        "â”‚   â””â”€â”€ classifier.pkl\n",
        "â”‚\n",
        "â”‚â”€â”€ notebook/\n",
        "â”‚   â””â”€â”€ face_recognition_demo.ipynb\n",
        "â”‚\n",
        "â”‚â”€â”€ src/\n",
        "â”‚   â”œâ”€â”€ train_model.py\n",
        "â”‚   â”œâ”€â”€ test_model.py\n",
        "â”‚   â””â”€â”€ utils.py (optional)\n",
        "â”‚\n",
        "â”‚â”€â”€ outputs/\n",
        "â”‚   â””â”€â”€ attendance.csv\n",
        "â”‚\n",
        "â”‚â”€â”€ requirements.txt\n",
        "â”‚â”€â”€ README.md\n",
        "â”‚â”€â”€ .gitignore\n",
        "```\n",
        "\n",
        "**Note:** This notebook assumes it lives inside `notebook/`. All paths are resolved relative to the project root (`..`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ccbc7c",
      "metadata": {},
      "source": [
        "## 1) Setup & Imports\n",
        "Install dependencies (if needed) and import libraries. If you're running inside a fresh environment, uncomment the pip command to install from `requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "756175dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE_DIR: d:\\python\\MachineLearning\\face-recognition-attendance-system\n",
            "DATA_DIR: d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\n",
            "MODELS_DIR: d:\\python\\MachineLearning\\face-recognition-attendance-system\\models\n",
            "OUTPUTS_DIR: d:\\python\\MachineLearning\\face-recognition-attendance-system\\outputs\n"
          ]
        }
      ],
      "source": [
        "# Optional: install dependencies from the repo root\n",
        "# !pip install -r ../requirements.txt\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Resolve key paths relative to this notebook (located in ../notebook)\n",
        "\n",
        "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "OUTPUTS_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
        "\n",
        "ATTENDANCE_FILE = os.path.join(OUTPUTS_DIR, \"attendance.csv\")\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"MODELS_DIR:\", MODELS_DIR)\n",
        "print(\"OUTPUTS_DIR:\", OUTPUTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b3a702",
      "metadata": {},
      "source": [
        "## 2) Dataset Preparation\n",
        "Images should be placed in `../data/<person_name>/image.jpg`. We will:\n",
        "\n",
        "- Load each image\n",
        "- Detect the face and compute a 128-D embedding using `face_recognition`\n",
        "- Build arrays: `encodings` (features) and `labels` (person names)\n",
        "\n",
        "If an image doesn't contain a detectable face, it will be skipped with a warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6c1eefed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\1.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\2.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\3.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\4.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\5.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Elon Musk\\6.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Jeff Bezos\\1.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Jeff Bezos\\2.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Jeff Bezos\\3.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Jeff Bezos\\4.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Jeff Bezos\\5.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Mark Zucker Burg\\1.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Mark Zucker Burg\\2.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Mark Zucker Burg\\3.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Mark Zucker Burg\\4.jpeg...\n",
            "Processing d:\\python\\MachineLearning\\face-recognition-attendance-system\\data\\Mark Zucker Burg\\5.jpeg...\n",
            "Found 3 unique classes.\n",
            "Number of encodings: 16\n",
            "Encodings shape: (16, 128)\n",
            "Number of labels: 16\n",
            "Unique classes: ['Elon Musk' 'Jeff Bezos' 'Mark Zucker Burg']\n"
          ]
        }
      ],
      "source": [
        "def get_face_encodings(image_path):\n",
        "    \"\"\"Return the 128-D face encoding for the first face found in the image, or None.\"\"\"\n",
        "    try:\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        encs = face_recognition.face_encodings(image)\n",
        "        if encs:\n",
        "            return encs[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "def prepare_dataset(dataset_path):\n",
        "    labels = []\n",
        "    encodings = []\n",
        "    if not os.path.isdir(dataset_path):\n",
        "        raise FileNotFoundError(f\"Dataset path not found: {dataset_path}\")\n",
        "\n",
        "    for person_name in os.listdir(dataset_path):\n",
        "        person_folder = os.path.join(dataset_path, person_name)\n",
        "        if os.path.isdir(person_folder):\n",
        "            for image_name in os.listdir(person_folder):\n",
        "                image_path = os.path.join(person_folder, image_name)\n",
        "                print(f\"Processing {image_path}...\")\n",
        "                encoding = get_face_encodings(image_path)\n",
        "                if encoding is not None:\n",
        "                    encodings.append(encoding)\n",
        "                    labels.append(person_name)\n",
        "                else:\n",
        "                    print(f\"Warning: No encoding found for image: {image_path}\")\n",
        "    print(f\"Found {len(np.unique(labels))} unique classes.\")\n",
        "    return np.array(encodings), np.array(labels)\n",
        "\n",
        "encodings, labels = prepare_dataset(DATA_DIR)\n",
        "print(f\"Number of encodings: {len(encodings)}\")\n",
        "print(f\"Encodings shape: {encodings.shape if encodings.size else 'Empty'}\")\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "print(f\"Unique classes: {np.unique(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69aa42c",
      "metadata": {},
      "source": [
        "## 3) Train the Classifier (SVM)\n",
        "We split the data into train/test sets and train a simple SVM (`svm.SVC`) on the embeddings. \n",
        "\n",
        "**Why this works:** `face_recognition` already gives a strong embedding where same-person faces are close together in the 128-D space. A linear or RBF SVM can then separate classes effectively.\n",
        "\n",
        "If you only have one class (one person) or too few images, training will fail â€” add more data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "de0345b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set classes: (array(['Elon Musk', 'Jeff Bezos', 'Mark Zucker Burg'], dtype='<U16'), array([4, 4, 4], dtype=int64))\n",
            "Testing set classes: (array(['Elon Musk', 'Jeff Bezos', 'Mark Zucker Burg'], dtype='<U16'), array([2, 1, 1], dtype=int64))\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "if encodings.size == 0 or len(labels) == 0:\n",
        "    raise RuntimeError(\"No encodings or labels found. Check your dataset in ../data.\")\n",
        "\n",
        "if len(np.unique(labels)) < 2:\n",
        "    raise RuntimeError(\"Less than 2 unique classes found. Add more people to ../data.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encodings, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(\"Training set classes:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Testing set classes:\", np.unique(y_test, return_counts=True))\n",
        "\n",
        "clf = svm.SVC(gamma='scale')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b19e112",
      "metadata": {},
      "source": [
        "## 4) Save Artifacts to `../models/`\n",
        "We persist two files so we can reuse them without retraining:\n",
        "\n",
        "- `encodings.pkl`: numpy array of embeddings and their labels (for later retraining/expansion)\n",
        "- `classifier.pkl`: trained SVM classifier\n",
        "\n",
        "These mirror what scripts in `src/` generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "14792420",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved encodings â†’ d:\\python\\MachineLearning\\face-recognition-attendance-system\\models\\encodings.pkl\n",
            "Saved classifier â†’ d:\\python\\MachineLearning\\face-recognition-attendance-system\\models\\classifier.pkl\n"
          ]
        }
      ],
      "source": [
        "enc_path = os.path.join(MODELS_DIR, 'encodings.pkl')\n",
        "clf_path = os.path.join(MODELS_DIR, 'classifier.pkl')\n",
        "\n",
        "with open(enc_path, 'wb') as f:\n",
        "    pickle.dump((encodings, labels), f)\n",
        "\n",
        "with open(clf_path, 'wb') as f:\n",
        "    pickle.dump(clf, f)\n",
        "\n",
        "print(f\"Saved encodings â†’ {enc_path}\")\n",
        "print(f\"Saved classifier â†’ {clf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ffa0157",
      "metadata": {},
      "source": [
        "## 5) (Optional) Test on a Single Image\n",
        "Use the trained classifier + stored encodings to predict a person in a static image. This is handy for quick validation before trying the webcam.\n",
        "\n",
        "ðŸ‘‰ Place a test image at a known path (e.g., `../data/person1/some_image.jpg`) and update the `TEST_IMAGE_PATH` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf73e79",
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image_path, known_encodings, known_labels, clf):\n",
        "    image_bgr = cv2.imread(image_path)\n",
        "    if image_bgr is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(image_rgb)\n",
        "    encs = face_recognition.face_encodings(image_rgb, boxes)\n",
        "\n",
        "    results = []\n",
        "    for enc, (top, right, bottom, left) in zip(encs, boxes):\n",
        "        # Option A: classifier prediction (trained SVM)\n",
        "        pred_name = clf.predict([enc])[0]\n",
        "        results.append((pred_name, (top, right, bottom, left)))\n",
        "    return image_bgr, results\n",
        "\n",
        "# Example usage (uncomment and set a valid path):\n",
        "# TEST_IMAGE_PATH = os.path.join(DATA_DIR, 'Mark Zucker Burg', '1.jpeg')\n",
        "# with open(os.path.join(MODELS_DIR, 'classifier.pkl'), 'rb') as f:\n",
        "#     loaded_clf = pickle.load(f)\n",
        "# with open(os.path.join(MODELS_DIR, 'encodings.pkl'), 'rb') as f:\n",
        "#     loaded_encs, loaded_labels = pickle.load(f)\n",
        "# img, preds = predict_image(TEST_IMAGE_PATH, loaded_encs, loaded_labels, loaded_clf)\n",
        "# for name, (t,r,b,l) in preds:\n",
        "#     cv2.rectangle(img, (l,t), (r,b), (0,255,0), 2)\n",
        "#     cv2.putText(img, name, (l, t-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
        "# cv2.imshow('Prediction', img)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adad0e85",
      "metadata": {},
      "source": [
        "## 6) Attendance Logging\n",
        "When a face is recognized, we log it to `../outputs/attendance.csv` **once per person per day**. The logic is:\n",
        "\n",
        "- If the CSV doesn't exist, create it with a header\n",
        "- If the person is already logged today, skip\n",
        "- Otherwise, append a new row with `Name, Date, Time`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b622ad2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mark_attendance(name, filename=ATTENDANCE_FILE):\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime('%Y-%m-%d')   # Date\n",
        "    tm_string = now.strftime('%H:%M:%S')   # Time\n",
        "\n",
        "    file_exists = os.path.isfile(filename)\n",
        "\n",
        "    # Ensure header exists\n",
        "    if not file_exists:\n",
        "        with open(filename, 'w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"Name\", \"Date\", \"Time\"])\n",
        "\n",
        "    # Check if this name already has attendance for today\n",
        "    with open(filename, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)  # skip header\n",
        "        for row in reader:\n",
        "            if len(row) >= 2 and row[0] == name and row[1] == dt_string:\n",
        "                print(f\"{name} already marked for {dt_string}\")\n",
        "                return\n",
        "\n",
        "    # Append new record\n",
        "    with open(filename, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([name, dt_string, tm_string])\n",
        "        print(f\"Attendance marked for {name} at {dt_string} {tm_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cca99631",
      "metadata": {},
      "source": [
        "## 7) Real-Time Recognition (Webcam)\n",
        "This cell starts your webcam and performs real-time face recognition. For each new person recognized in the current session, attendance is logged once per day.\n",
        "\n",
        "**Controls:** Press `q` to quit.\n",
        "\n",
        "**Note:** `face_recognition` expects RGB images, while OpenCV captures in BGR. We convert BGR â†’ RGB before encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256fcc64",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elon Musk already marked for 2025-08-30\n"
          ]
        }
      ],
      "source": [
        "def recognize_faces(frame, clf, known_encodings, known_labels, distance_threshold=0.6):\n",
        "    # Convert BGR â†’ RGB for face_recognition\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    face_locations = face_recognition.face_locations(rgb)\n",
        "    face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
        "    names = []\n",
        "\n",
        "    for face_encoding in face_encodings:\n",
        "        # Compute distances to all known encodings\n",
        "        distances = np.linalg.norm(known_encodings - face_encoding, axis=1)\n",
        "        min_distance = np.min(distances)\n",
        "\n",
        "        if min_distance < distance_threshold:\n",
        "            # If within threshold, let classifier decide\n",
        "            try:\n",
        "                name = clf.predict([face_encoding])[0]\n",
        "            except:\n",
        "                name = \"Unknown\"\n",
        "        else:\n",
        "            name = \"Unknown\"\n",
        "\n",
        "        names.append(name)\n",
        "\n",
        "    return face_locations, names\n",
        "\n",
        "\n",
        "def run_webcam_recognition():\n",
        "    # Load classifier\n",
        "    with open(os.path.join(MODELS_DIR, 'classifier.pkl'), 'rb') as f:\n",
        "        clf = pickle.load(f)\n",
        "\n",
        "    # Load encodings\n",
        "    with open(os.path.join(MODELS_DIR, 'encodings.pkl'), 'rb') as f:\n",
        "        known_encodings, known_labels = pickle.load(f)\n",
        "\n",
        "    recognized_names = set()\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(\"Could not open webcam. Is a camera available?\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture image from camera.\")\n",
        "            break\n",
        "\n",
        "        face_locations, names = recognize_faces(frame, clf, known_encodings, known_labels)\n",
        "        for (top, right, bottom, left), name in zip(face_locations, names):\n",
        "            if name != \"Unknown\" and name not in recognized_names:\n",
        "                recognized_names.add(name)\n",
        "                mark_attendance(name)\n",
        "\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow('Face Recognition - Press q to quit', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "run_webcam_recognition()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "020538fc",
      "metadata": {},
      "source": [
        "## 8) Notes, Troubleshooting & Next Steps\n",
        "- **Lighting & camera angle:** Bad lighting or extreme angles reduce accuracy.\n",
        "- **Image quality:** Use clear, frontal images for each person (several per person recommended).\n",
        "- **Thresholds:** You can adjust SVM parameters or switch to distance-based matching with a threshold (e.g., 0.6) against saved encodings.\n",
        "- **Liveness/anti-spoofing:** This simple system can be fooled by phone photos. To mitigate, consider adding liveness detection (eye blink, depth/IR camera, texture analysis, challenge-response).\n",
        "- **Per-day CSV:** Currently logs to a single `attendance.csv`. You can change to daily files like `attendance_YYYY-MM-DD.csv` if needed.\n",
        "- **Performance:** For many users, consider caching encodings, using GPU-accelerated libraries, or batching frames.\n",
        "\n",
        "If you encounter issues, verify:\n",
        "1) Paths (`DATA_DIR`, `MODELS_DIR`, `OUTPUTS_DIR`) are correct\n",
        "2) Camera is available and accessible\n",
        "3) You have at least 2 classes and enough images per class"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
